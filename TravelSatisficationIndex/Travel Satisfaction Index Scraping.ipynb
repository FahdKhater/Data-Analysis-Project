{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "929ef463-32bd-4ba8-9daa-30a23169094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e497f44-3612-47ac-95ff-9480193e735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CITIES = [\n",
    "    \"Paris\", \"Barcelona\", \"Tokyo\", \"New York\", \"London, United Kingdom\",\n",
    "    \"Rome\", \"Amsterdam\", \"Sydney\", \"Bangkok\", \"Istanbul\", \n",
    "    \"Cairo\", \"Rio de Janeiro\", \"Venice\", \"Los Angeles\"\n",
    "]\n",
    "\n",
    "MANUAL_URLS = {\n",
    "    \"Venice\": \"https://www.numbeo.com/quality-of-life/in/Venice\",\n",
    "    \"Rio de Janeiro\": \"https://www.numbeo.com/quality-of-life/in/Rio-De-Janeiro\",\n",
    "    \"Los Angeles\": \"https://www.numbeo.com/quality-of-life/in/Los-Angeles\"\n",
    "}\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2e15cb-7cb4-4a02-875f-6cf5979f4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_global_rankings():\n",
    "    \"\"\"Scrapes the main Numbeo Quality of Life ranking table.\"\"\"\n",
    "    url = \"https://www.numbeo.com/quality-of-life/rankings_current.jsp\"\n",
    "    print(f\"Fetching global data from {url}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        table = soup.find('table', {'id': 't2'})\n",
    "        \n",
    "        if not table: return pd.DataFrame()\n",
    "        \n",
    "        headers = [th.get_text(strip=True) for th in table.find('tr').find_all('th')]\n",
    "        rows = []\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            cells = [td.get_text(strip=True) for td in row.find_all('td')]\n",
    "            if len(cells) == len(headers):\n",
    "                rows.append(cells)\n",
    "                \n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "        \n",
    "        traffic_col = next((c for c in df.columns if 'Traffic' in c), 'Traffic Commute Time Index')\n",
    "        return df.rename(columns={\n",
    "            'City': 'City', \n",
    "            'Safety Index': 'Safety', \n",
    "            'Pollution Index': 'Pollution', \n",
    "            'Climate Index': 'Climate',\n",
    "            traffic_col: 'Traffic'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Global scrape error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def scrape_city_details(city_name, url=None):\n",
    "    \"\"\"Scrapes specific city details if missing from global list.\"\"\"\n",
    "    if not url:\n",
    "        clean_name = city_name.replace(\" \", \"-\").title()\n",
    "        url = f\"https://www.numbeo.com/quality-of-life/in/{clean_name}\"\n",
    "\n",
    "    print(f\"Force-scraping: {city_name}...\")\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        if response.status_code != 200: return None\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        data = {'City': city_name}\n",
    "        all_cells = soup.find_all('td')\n",
    "        \n",
    "        label_map = {\n",
    "            \"Safety Index\": \"Safety\",\n",
    "            \"Pollution Index\": \"Pollution\",\n",
    "            \"Climate Index\": \"Climate\",\n",
    "            \"Traffic Commute Time Index\": \"Traffic\"\n",
    "        }\n",
    "\n",
    "        for i, cell in enumerate(all_cells):\n",
    "            text = cell.get_text(strip=True)\n",
    "            for label, key in label_map.items():\n",
    "                if label in text:\n",
    "                    try:\n",
    "                        val = all_cells[i+1].get_text(strip=True)\n",
    "                        if \":\" not in val: # Avoid grabbing labels\n",
    "                            data[key] = val\n",
    "                    except IndexError: pass\n",
    "        \n",
    "        return data if 'Safety' in data else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {city_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_satisfaction_index(df):\n",
    "    \"\"\"Cleans data and calculates the custom Travel Satisfaction Index.\"\"\"\n",
    "    cols = ['Safety', 'Pollution', 'Traffic', 'Climate']\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    df = df.dropna(subset=cols).copy()\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df['N_Safety'] = scaler.fit_transform(df[['Safety']])\n",
    "    df['N_Climate'] = scaler.fit_transform(df[['Climate']])\n",
    "    \n",
    "    # Invert negative metrics (Pollution/Traffic) so higher is better\n",
    "    df['N_Pollution'] = 1 - scaler.fit_transform(df[['Pollution']])\n",
    "    df['N_Traffic'] = 1 - scaler.fit_transform(df[['Traffic']])\n",
    "    \n",
    "    # Weighted Score Calculation\n",
    "    df['Travel_Score'] = (\n",
    "        (df['N_Safety'] * 0.4) + \n",
    "        (df['N_Climate'] * 0.2) +\n",
    "        (df['N_Pollution'] * 0.2) + \n",
    "        (df['N_Traffic'] * 0.2)\n",
    "    ) * 100\n",
    "    \n",
    "    return df.sort_values('Travel_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4255c3b-3891-4ce3-82b0-b4c7093a5a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching global data from https://www.numbeo.com/quality-of-life/rankings_current.jsp...\n",
      "Missing cities found: {'Venice'}\n",
      "Force-scraping: Venice...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tamer\\AppData\\Local\\Temp\\ipykernel_10304\\2138915885.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Target_City</th>\n",
       "      <th>Travel_Score</th>\n",
       "      <th>Safety</th>\n",
       "      <th>Pollution</th>\n",
       "      <th>Traffic</th>\n",
       "      <th>Climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>94.559718</td>\n",
       "      <td>74.30</td>\n",
       "      <td>22.60</td>\n",
       "      <td>22.10</td>\n",
       "      <td>87.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>79.129574</td>\n",
       "      <td>66.10</td>\n",
       "      <td>28.60</td>\n",
       "      <td>43.30</td>\n",
       "      <td>97.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>76.163917</td>\n",
       "      <td>74.90</td>\n",
       "      <td>43.00</td>\n",
       "      <td>42.70</td>\n",
       "      <td>85.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rome</td>\n",
       "      <td>65.291093</td>\n",
       "      <td>52.70</td>\n",
       "      <td>48.80</td>\n",
       "      <td>35.30</td>\n",
       "      <td>93.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Venice</td>\n",
       "      <td>62.355293</td>\n",
       "      <td>68.04</td>\n",
       "      <td>64.18</td>\n",
       "      <td>43.75</td>\n",
       "      <td>82.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>61.495503</td>\n",
       "      <td>48.10</td>\n",
       "      <td>63.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>95.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>50.097369</td>\n",
       "      <td>52.00</td>\n",
       "      <td>67.30</td>\n",
       "      <td>50.80</td>\n",
       "      <td>93.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>London</td>\n",
       "      <td>47.725250</td>\n",
       "      <td>44.40</td>\n",
       "      <td>58.10</td>\n",
       "      <td>44.80</td>\n",
       "      <td>88.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>New York</td>\n",
       "      <td>47.673184</td>\n",
       "      <td>48.90</td>\n",
       "      <td>57.90</td>\n",
       "      <td>43.50</td>\n",
       "      <td>79.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>Paris</td>\n",
       "      <td>46.353220</td>\n",
       "      <td>42.00</td>\n",
       "      <td>63.40</td>\n",
       "      <td>41.20</td>\n",
       "      <td>88.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>42.548846</td>\n",
       "      <td>45.90</td>\n",
       "      <td>68.40</td>\n",
       "      <td>57.20</td>\n",
       "      <td>95.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>40.343583</td>\n",
       "      <td>61.80</td>\n",
       "      <td>77.70</td>\n",
       "      <td>44.90</td>\n",
       "      <td>58.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>39.948820</td>\n",
       "      <td>50.00</td>\n",
       "      <td>90.60</td>\n",
       "      <td>49.70</td>\n",
       "      <td>88.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>25.554614</td>\n",
       "      <td>24.80</td>\n",
       "      <td>67.70</td>\n",
       "      <td>51.20</td>\n",
       "      <td>88.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank     Target_City  Travel_Score  Safety  Pollution  Traffic  Climate\n",
       "0      1       Amsterdam     94.559718   74.30      22.60    22.10    87.50\n",
       "1      2          Sydney     79.129574   66.10      28.60    43.30    97.10\n",
       "2      3           Tokyo     76.163917   74.90      43.00    42.70    85.30\n",
       "4      4            Rome     65.291093   52.70      48.80    35.30    93.70\n",
       "13     5          Venice     62.355293   68.04      64.18    43.75    82.39\n",
       "3      6       Barcelona     61.495503   48.10      63.00    30.00    95.70\n",
       "9      7        Istanbul     50.097369   52.00      67.30    50.80    93.00\n",
       "6      8          London     47.725250   44.40      58.10    44.80    88.30\n",
       "8      9        New York     47.673184   48.90      57.90    43.50    79.70\n",
       "5     10           Paris     46.353220   42.00      63.40    41.20    88.40\n",
       "7     11     Los Angeles     42.548846   45.90      68.40    57.20    95.50\n",
       "10    12         Bangkok     40.343583   61.80      77.70    44.90    58.40\n",
       "12    13           Cairo     39.948820   50.00      90.60    49.70    88.50\n",
       "11    14  Rio de Janeiro     25.554614   24.80      67.70    51.20    88.20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_global = get_global_rankings()\n",
    "\n",
    "found_data = []\n",
    "found_cities = set()\n",
    "\n",
    "for _, row in df_global.iterrows():\n",
    "    city_lower = row['City'].lower()\n",
    "    for target in TARGET_CITIES:\n",
    "        if city_lower.startswith(target.lower() + \",\") or city_lower == target.lower():\n",
    "            row_dict = row.to_dict()\n",
    "            row_dict['Target_City'] = target\n",
    "            found_data.append(row_dict)\n",
    "            found_cities.add(target)\n",
    "            break\n",
    "\n",
    "missing_cities = set(TARGET_CITIES) - found_cities\n",
    "if missing_cities:\n",
    "    print(f\"Missing cities found: {missing_cities}\")\n",
    "    for city in missing_cities:\n",
    "        city_data = scrape_city_details(city, url=MANUAL_URLS.get(city))\n",
    "        if city_data:\n",
    "            city_data['Target_City'] = city\n",
    "            found_data.append(city_data)\n",
    "\n",
    "if found_data:\n",
    "    df_final = pd.DataFrame(found_data)\n",
    "    \n",
    "    cols_needed = ['Target_City', 'Safety', 'Pollution', 'Traffic', 'Climate']\n",
    "\n",
    "    for c in cols_needed:\n",
    "        if c not in df_final.columns: df_final[c] = None\n",
    "            \n",
    "    df_scored = calculate_satisfaction_index(df_final[cols_needed])\n",
    "    df_scored = df_scored.sort_values('Travel_Score', ascending=False).drop_duplicates(subset=['Target_City'], keep='first')\n",
    "    df_scored['Target_City'] = df_scored['Target_City'].replace('London, United Kingdom', 'London')\n",
    "    df_scored.insert(0, 'Rank', range(1, len(df_scored) + 1))\n",
    "    \n",
    "    display(df_scored[['Rank', 'Target_City', 'Travel_Score', 'Safety', 'Pollution', 'Traffic', 'Climate']])\n",
    "else:\n",
    "    print(\"No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed5effae-2cfc-4efe-b332-d4b26ab2a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_scored' in locals() and not df_scored.empty: \n",
    "    # Clean up helper columns (Normalized columns) before saving\n",
    "    output_cols = ['Rank', 'Target_City', 'Travel_Score', 'Safety', 'Pollution', 'Traffic', 'Climate']\n",
    "    df_scored[output_cols].to_csv(\"Travel_Satisfaction_Index.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
